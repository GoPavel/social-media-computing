{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import display\n",
    "show = display\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# Gender prediction\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Twitter'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## RF'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LDA50Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.7318952807421664, f1score: 0.724711129113902'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LIWCFeatures'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.6921710398071553, f1score: 0.6814599894179255'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ManuallyDefinedTextFeatures'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.6652119448486109, f1score: 0.6524614766023734'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Ada boost'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LDA50Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.7105725487396736, f1score: 0.7036657072713572'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LIWCFeatures'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.6888950967929693, f1score: 0.67970883891651'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ManuallyDefinedTextFeatures'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.6641510427492552, f1score: 0.6469342255292789'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Linear SVC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LDA50Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.699319525246341, f1score: 0.6855360505414763'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LIWCFeatures'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.693106984303917, f1score: 0.6765390374056139'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ManuallyDefinedTextFeatures'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.6397842444398254, f1score: 0.581810388189633'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(\"# Twitter\")\n",
    "\n",
    "lda, liwc, mtf = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "train = pd.DataFrame()\n",
    "\n",
    "# TODO add city as feature\n",
    "for city, city_train in [(\"NewYork\", \"NY\"), (\"London\", \"London\"), (\"Singapore\", \"Singapore\")]:\n",
    "    lda = pd.concat([lda, pd.read_csv(f\"data/Features/features{city}/Twitter/LDA50Features.csv\", encoding=\"ISO-8859-15\")], axis=0, ignore_index=True)\n",
    "    liwc = pd.concat([liwc, pd.read_csv(f\"data/Features/features{city}/Twitter/LIWCFeatures.csv\", encoding=\"ISO-8859-15\")], axis=0, ignore_index=True)\n",
    "    mtf = pd.concat([mtf, pd.read_csv(f\"data/Features/features{city}/Twitter/manuallyDefinedTextFeatures.csv\", encoding=\"ISO-8859-15\")], axis=0, ignore_index=True)\n",
    "\n",
    "    train = pd.concat([train, pd.read_csv(f\"data/{city_train}Train.csv\")], axis=0, ignore_index=True)\n",
    "\n",
    "lda = lda.drop_duplicates(subset=[\"_id\"], ignore_index=True)\n",
    "liwc = liwc.drop_duplicates(subset=[\"_id\"], ignore_index=True)\n",
    "mtf = mtf.drop_duplicates(subset=[\"_id\"], ignore_index=True)\n",
    "train = train.drop_duplicates(subset=[\"row ID\"], ignore_index=True)\n",
    "\n",
    "with joblib.parallel_backend(\"multiprocessing\"): \n",
    "\n",
    "    show(\"## RF\")\n",
    "    for data, feature_name in zip([lda, liwc, mtf], [\"LDA50Features\", \"LIWCFeatures\", \"ManuallyDefinedTextFeatures\"]):\n",
    "        show(feature_name)\n",
    "             \n",
    "        df = data.merge(train, left_on='_id', right_on='row ID')\n",
    "        df = df.dropna(subset=[\"gender\"])\n",
    "\n",
    "        Y = df[\"gender\"].values\n",
    "        X = df.drop([*train.columns, \"_id\"], axis=1).values\n",
    "        \n",
    "        fscore, accuracy = [], []\n",
    "        fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        for train_ix, test_ix in fold10.split(X, Y):\n",
    "            clf = RandomForestClassifier(n_estimators=30, max_depth=300, min_samples_split=2, random_state=42)\n",
    "            clf.fit(X[train_ix], Y[train_ix])\n",
    "            y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "            accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "            fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "        accuracy = np.array(accuracy).mean(axis=0)\n",
    "        fscore = np.array(fscore).mean(axis=0)\n",
    "        show(f\"accur: {accuracy}, f1score: {fscore}\")\n",
    "\n",
    "    show(\"## Ada boost\")    \n",
    "    for data, feature_name in zip([lda, liwc, mtf], [\"LDA50Features\", \"LIWCFeatures\", \"ManuallyDefinedTextFeatures\"]):\n",
    "        show(feature_name)\n",
    "        \n",
    "        df = data.merge(train, left_on='_id', right_on='row ID')\n",
    "        df = df.dropna(subset=[\"gender\"])\n",
    "\n",
    "        Y = df[\"gender\"].values\n",
    "        X = df.drop([*train.columns, \"_id\"], axis=1).values\n",
    "\n",
    "        fscore, accuracy = [], []\n",
    "        fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        for train_ix, test_ix in fold10.split(X, Y):\n",
    "            clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "            clf.fit(X[train_ix], Y[train_ix])\n",
    "            y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "            accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "            fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "        accuracy = np.array(accuracy).mean(axis=0)\n",
    "        fscore = np.array(fscore).mean(axis=0)\n",
    "        show(f\"accur: {accuracy}, f1score: {fscore}\")\n",
    "        \n",
    "    show(\"## Linear SVC\")    \n",
    "    for data, feature_name in zip([lda, liwc, mtf], [\"LDA50Features\", \"LIWCFeatures\", \"ManuallyDefinedTextFeatures\"]):\n",
    "        show(feature_name)\n",
    "                \n",
    "        df = data.merge(train, left_on='_id', right_on='row ID')\n",
    "        df = df.dropna(subset=[\"gender\"])\n",
    "\n",
    "        Y = df[\"gender\"].values\n",
    "        X = df.drop([*train.columns, \"_id\"], axis=1).values\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        fscore, accuracy = [], []\n",
    "        fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        for train_ix, test_ix in fold10.split(X, Y):\n",
    "            clf = LinearSVC(max_iter=1000)\n",
    "            clf.fit(X[train_ix], Y[train_ix])\n",
    "            y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "            accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "            fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "        accuracy = np.array(accuracy).mean(axis=0)\n",
    "        fscore = np.array(fscore).mean(axis=0)\n",
    "        show(f\"accur: {accuracy}, f1score: {fscore}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Instagram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## RF'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.673686750274058, f1score: 0.6689067642636951'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Ada boost'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.5866802515564926, f1score: 0.5566290042688148'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Linear SVC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/gopavel/.cache/pypoetry/virtualenvs/social-media-computing-zp_zk-1p-py3.7/lib64/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.5900872265319717, f1score: 0.4700363761773512'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(\"# Instagram\")\n",
    "\n",
    "image_concepts = pd.DataFrame()\n",
    "train = pd.DataFrame()\n",
    "\n",
    "# TODO add city as feature\n",
    "for city, city_train in [(\"NewYork\", \"NY\"), (\"London\", \"London\"), (\"Singapore\", \"Singapore\")]:\n",
    "    image_concepts = pd.concat([image_concepts, pd.read_csv(f\"data/Features/features{city}/Instagram/imageConceptsFeatures.csv\", encoding=\"ISO-8859-15\")], axis=0, ignore_index=True)\n",
    "  \n",
    "    train = pd.concat([train, pd.read_csv(f\"data/{city_train}Train.csv\")], axis=0, ignore_index=True)\n",
    "\n",
    "image_concepts = image_concepts.drop_duplicates(subset=[\"_id\"], ignore_index=True)\n",
    "train = train.drop_duplicates(subset=[\"row ID\"], ignore_index=True)\n",
    "\n",
    "with joblib.parallel_backend(\"multiprocessing\"): \n",
    "\n",
    "    show(\"## RF\")\n",
    "\n",
    "    data = image_concepts\n",
    "    df = data.merge(train, left_on='_id', right_on='row ID')\n",
    "    df = df.dropna(subset=[\"gender\"])\n",
    "\n",
    "    Y = df[\"gender\"].values\n",
    "    X = df.drop([*train.columns, \"_id\"], axis=1).values\n",
    "\n",
    "    fscore, accuracy = [], []\n",
    "    fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_ix, test_ix in fold10.split(X, Y):\n",
    "        clf = RandomForestClassifier(n_estimators=30, max_depth=300, min_samples_split=2, random_state=42)\n",
    "        clf.fit(X[train_ix], Y[train_ix])\n",
    "        y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "        accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "        fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "    accuracy = np.array(accuracy).mean(axis=0)\n",
    "    fscore = np.array(fscore).mean(axis=0)\n",
    "    show(f\"accur: {accuracy}, f1score: {fscore}\")\n",
    "\n",
    "    show(\"## Ada boost\")    \n",
    "        \n",
    "    fscore, accuracy = [], []\n",
    "    fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_ix, test_ix in fold10.split(X, Y):\n",
    "        clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "        clf.fit(X[train_ix], Y[train_ix])\n",
    "        y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "        accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "        fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "    accuracy = np.array(accuracy).mean(axis=0)\n",
    "    fscore = np.array(fscore).mean(axis=0)\n",
    "    show(f\"accur: {accuracy}, f1score: {fscore}\")\n",
    "        \n",
    "    show(\"## Linear SVC\")    \n",
    "     \n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "        \n",
    "    fscore, accuracy = [], []\n",
    "    fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_ix, test_ix in fold10.split(X, Y):\n",
    "        clf = LinearSVC(max_iter=1000)\n",
    "        clf.fit(X[train_ix], Y[train_ix])\n",
    "        y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "        accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "        fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "    accuracy = np.array(accuracy).mean(axis=0)\n",
    "    fscore = np.array(fscore).mean(axis=0)\n",
    "    show(f\"accur: {accuracy}, f1score: {fscore}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Foursquare'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## RF'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.6102399301542154, f1score: 0.5973504087991597'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Ada boost'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.636132426948832, f1score: 0.6003453292626075'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## Linear SVC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'accur: 0.6234775458431601, f1score: 0.5502709435409617'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(\"# Foursquare\")\n",
    "\n",
    "lda6 = pd.DataFrame()\n",
    "train = pd.DataFrame()\n",
    "\n",
    "# TODO add city as feature\n",
    "for city, city_train in [(\"NewYork\", \"NY\"), (\"London\", \"London\"), (\"Singapore\", \"Singapore\")]:\n",
    "    lda6 = pd.concat([lda6, pd.read_csv(f\"data/Features/features{city}/Foursquare/venueCategoriesLDA6Features.csv\", encoding=\"ISO-8859-15\")], axis=0, ignore_index=True)\n",
    "\n",
    "    train = pd.concat([train, pd.read_csv(f\"data/{city_train}Train.csv\")], axis=0, ignore_index=True)\n",
    "\n",
    "lda6 = lda6.drop_duplicates(subset=[\"_id\"], ignore_index=True)\n",
    "train = train.drop_duplicates(subset=[\"row ID\"], ignore_index=True)\n",
    "\n",
    "with joblib.parallel_backend(\"multiprocessing\"): \n",
    "\n",
    "    show(\"## RF\")\n",
    "    \n",
    "    data = lda6\n",
    "    df = data.merge(train, left_on='_id', right_on='row ID')\n",
    "    df = df.dropna(subset=[\"gender\"])\n",
    "\n",
    "    Y = df[\"gender\"].values\n",
    "    X = df.drop([*train.columns, \"_id\"], axis=1).values\n",
    "\n",
    "    fscore, accuracy = [], []\n",
    "    fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_ix, test_ix in fold10.split(X, Y):\n",
    "        clf = RandomForestClassifier(n_estimators=30, max_depth=300, min_samples_split=2, random_state=42)\n",
    "        clf.fit(X[train_ix], Y[train_ix])\n",
    "        y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "        accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "        fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "    accuracy = np.array(accuracy).mean(axis=0)\n",
    "    fscore = np.array(fscore).mean(axis=0)\n",
    "    show(f\"accur: {accuracy}, f1score: {fscore}\")\n",
    "\n",
    "    show(\"## Ada boost\")    \n",
    "        \n",
    "    fscore, accuracy = [], []\n",
    "    fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_ix, test_ix in fold10.split(X, Y):\n",
    "        clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "        clf.fit(X[train_ix], Y[train_ix])\n",
    "        y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "        accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "        fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "    accuracy = np.array(accuracy).mean(axis=0)\n",
    "    fscore = np.array(fscore).mean(axis=0)\n",
    "    show(f\"accur: {accuracy}, f1score: {fscore}\")\n",
    "        \n",
    "    show(\"## Linear SVC\")    \n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "        \n",
    "    fscore, accuracy = [], []\n",
    "    fold10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_ix, test_ix in fold10.split(X, Y):\n",
    "        clf = LinearSVC(max_iter=1000)\n",
    "        clf.fit(X[train_ix], Y[train_ix])\n",
    "        y_true, y_pred = Y[test_ix], clf.predict(X[test_ix])\n",
    "        accuracy.append(skm.accuracy_score(y_true, y_pred))\n",
    "        fscore.append(skm.f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "    accuracy = np.array(accuracy).mean(axis=0)\n",
    "    fscore = np.array(fscore).mean(axis=0)\n",
    "    show(f\"accur: {accuracy}, f1score: {fscore}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
